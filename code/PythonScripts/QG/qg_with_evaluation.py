# -*- coding: utf-8 -*-
"""QG With Evaluation.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1fdV9SDP1OisOpUcTVTnpWL0f2X0wE_SE

LAST UPDATE 27/4 BY Labib

# Package Installations
"""

!pip install transformers
!pip install datasets
!pip install evaluate

"""# QG Model

**Mostly from:**


> https://colab.research.google.com/github/snapthat/TF-T5-text-to-text/blob/master/snapthatT5/notebooks/TF-T5-Datasets%20Training.ipynb#scrollTo=2ihk1kxxDXO_

## Imports
"""

import datasets
from datasets import load_dataset
from datasets import Dataset
import tensorflow as tf
import numpy as np
import matplotlib.pyplot as plt
import tensorflow_datasets as tfds
import transformers
from transformers import AutoTokenizer, TFT5ForConditionalGeneration
import datetime
import os
from datasets import concatenate_datasets

"""## Hyperparameters"""

task_prefix = 'generate question using question word: '
learning_rate = 5e-5  # 3e-4
encoder_max_len = 250
decoder_max_len = 70
batch_size = 16

"""## Tokenizer & Optimizer"""

model_name = "t5-base"
tokenizer = AutoTokenizer.from_pretrained(model_name)
optimizer = tf.keras.optimizers.Adam(learning_rate)

"""## Dataset

Check if the dataset is saved in drive already
"""

from google.colab import drive
drive.mount('/content/drive')

from pathlib import Path

train_ds_file = Path(r'/content/drive/MyDrive/Datasets/squad-valid-encoded.json')
is_ds_saved = False
if train_ds_file.is_file():
    is_ds_saved = True
is_ds_saved

"""### Case 1: Dataset **NOT** saved on drive

Load squad dataset from "datasets" huggingface library
"""

if not is_ds_saved:
  train_dataset = load_dataset('squad', split='train')
  valid_dataset = load_dataset('squad', split='validation')

"""Show example from dataset

Output:



>  `{'id': '5733be284776f41900661182', 'title': 'University_of_Notre_Dame', 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend "Venite Ad Me Omnes". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.', 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?', 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}}`

Dataset features

Output:




> `{'id': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'context': Value(dtype='string', id=None), 'question': Value(dtype='string', id=None), 'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None)}`
"""

interrogative_words = ['who', 'what', 'when', 'where', 'why','how','which','whom','others']
def encode(example, encoder_max_len=encoder_max_len, decoder_max_len=decoder_max_len):
    global count
    context = example['context']
    question = example['question']
    answers = example['answers']['text']
    answers = ', '.join([i for i in list(answers)]) # Comma seperated answers ZZZ

    # generate question: John Doe, Jane Doe content: "John Doe and Jane Doe killed...."
    words=tokenizer.tokenize(question)
    found=False
    for word in words:
      word=word[1:]
      if word.lower() in interrogative_words:
        found=True
        input = task_prefix + word+ ' ' + 'answer:' + ' '+ answers + ' ' + 'context: ' + context
    if found==False:
      input = task_prefix + 'None'+ ' ' + 'answer:' + ' '+ answers + ' ' + 'context: ' + context
    # print(input)

    output = question

    encoder_inputs = tokenizer(input, truncation=True,
                               return_tensors='tf', max_length=encoder_max_len,
                              pad_to_max_length=True)
    decoder_inputs = tokenizer(output, truncation=True,
                               return_tensors='tf', max_length=decoder_max_len,
                              pad_to_max_length=True)

    # Shapes come from the encoder_max_len and decoder_max_len in hyperparameters section
    input_ids = encoder_inputs['input_ids'][0] # Shape before flattening: input_ids.shape= (1, 250) [[1,1,3,...]]
    input_attention = encoder_inputs['attention_mask'][0] # Shape before flattening: attension_mask.shape= (1, 250)
    target_ids = decoder_inputs['input_ids'][0] # Shape before flattening: target_ids.shape= (1, 70)
    target_attention = decoder_inputs['attention_mask'][0] # Shape before flattening: target_attention.shape= (1, 70)

    outputs = {'input_ids':input_ids, 'attention_mask': input_attention,
               'labels':target_ids, 'decoder_attention_mask':target_attention}
    return outputs

if not is_ds_saved:
  train_ds = train_dataset.map(encode)
  valid_ds = valid_dataset.map(encode)

"""Show example from encoded dataset


<details>
  <summary>Show output</summary>


> `{'id': '5733be284776f41900661182', 'title': 'University_of_Notre_Dame', 'context': 'Architecturally, the school has a Catholic character. Atop the Main Building\'s gold dome is a golden statue of the Virgin Mary. Immediately in front of the Main Building and facing it, is a copper statue of Christ with arms upraised with the legend "Venite Ad Me Omnes". Next to the Main Building is the Basilica of the Sacred Heart. Immediately behind the basilica is the Grotto, a Marian place of prayer and reflection. It is a replica of the grotto at Lourdes, France where the Virgin Mary reputedly appeared to Saint Bernadette Soubirous in 1858. At the end of the main drive (and in a direct line that connects through 3 statues and the Gold Dome), is a simple, modern stone statue of Mary.', 'question': 'To whom did the Virgin Mary allegedly appear in 1858 in Lourdes France?', 'answers': {'text': ['Saint Bernadette Soubirous'], 'answer_start': [515]}, 'input_ids': [3806, 822, 10, 2788, 8942, 9, 26, 1954, 264, 8371, 8283, 2625, 10, 30797, 120, 6, 8, 496, 65, 3, 9, 6502, 1848, 5, 71, 2916, 8, 5140, 5450, 31, 7, 2045, 22161, 19, 3, 9, 7069, 12647, 13, 8, 16823, 3790, 5, 3, 29167, 16, 851, 13, 8, 5140, 5450, 11, 5008, 34, 6, 19, 3, 9, 8658, 12647, 13, 2144, 28, 6026, 3, 76, 24266, 28, 8, 9503, 96, 553, 15, 7980, 1980, 1212, 13285, 1496, 1280, 3021, 12, 8, 5140, 5450, 19, 8, 23711, 2617, 13, 8, 3, 24756, 6219, 5, 3, 29167, 1187, 8, 20605, 2617, 19, 8, 8554, 17, 235, 6, 3, 9, 17535, 286, 13, 7029, 11, 9619, 5, 94, 19, 3, 9, 16455, 13, 8, 3, 3844, 17, 235, 44, 301, 1211, 1395, 6, 1410, 213, 8, 16823, 3790, 3, 28285, 26, 120, 4283, 12, 2788, 8942, 9, 26, 1954, 264, 8371, 8283, 16, 507, 3449, 5, 486, 8, 414, 13, 8, 711, 1262, 41, 232, 16, 3, 9, 1223, 689, 24, 1979, 7, 190, 220, 12647, 7, 11, 8, 2540, 10576, 15, 201, 19, 3, 9, 650, 6, 941, 3372, 12647, 13, 3790, 5, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'labels': [304, 4068, 410, 8, 16823, 3790, 3, 18280, 2385, 16, 507, 3449, 16, 301, 1211, 1395, 1410, 58, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'decoder_attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}`



</details>

Encoded dataset features

Output:



> `{'id': Value(dtype='string', id=None), 'title': Value(dtype='string', id=None), 'context': Value(dtype='string', id=None), 'question': Value(dtype='string', id=None), 'answers': Sequence(feature={'text': Value(dtype='string', id=None), 'answer_start': Value(dtype='int32', id=None)}, length=-1, id=None), 'input_ids': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'attention_mask': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'labels': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None), 'decoder_attention_mask': Sequence(feature=Value(dtype='int32', id=None), length=-1, id=None)}`

Save encoded dataset to google drive (requires to mount drive)
"""

if not is_ds_saved:
  train_ds.to_json("/content/drive/MyDrive/Datasets/squad-train-encoded.json")
  valid_ds.to_json("/content/drive/MyDrive/Datasets/squad-valid-encoded.json")

"""### Case 2: Dataset saved on drive

Load dataset from drive
"""

if is_ds_saved:
  squad_data_files = {
        "train": "/content/drive/MyDrive/Datasets/squad-train-encoded.json",
        "validation": "/content/drive/MyDrive/Datasets/squad-valid-encoded.json",
    }

  # msmarco_ds = load_dataset("json", data_files="/content/drive/MyDrive/Datasets/ms-marco-train-encoded.json")
  # newsqa_ds = load_dataset("json", data_files="/content/drive/MyDrive/Datasets/newsqa-train-encoded.json")
  adqa_train = load_dataset("json", data_files="/content/drive/MyDrive/Datasets/adversarial_qa-train-encoded.json")

  # squad_ds = load_dataset("json", data_files=squad_data_files, split='train')
  valid_ds = load_dataset("json", data_files=squad_data_files, split='validation')

# squad_ds = squad_ds.remove_columns(['id','title'])
# squad_ds = squad_ds.rename_column("answers", "answer")
train_ds = adqa_train['train']

# train_ds_1 = concatenate_datasets([newsqa_ds['train'] , msmarco_ds['train'] ])
# train_ds = concatenate_datasets([adqa_train['train'],squad_ds])

def to_tf_dataset(dataset):
  columns = ['input_ids', 'attention_mask', 'labels', 'decoder_attention_mask']
  dataset.set_format(type='tensorflow', columns=columns)
  return_types = {'input_ids':tf.int32, 'attention_mask':tf.int32,
                'labels':tf.int32, 'decoder_attention_mask':tf.int32,  }
  return_shapes = {'input_ids': tf.TensorShape([None]), 'attention_mask': tf.TensorShape([None]),
                  'labels': tf.TensorShape([None]), 'decoder_attention_mask':tf.TensorShape([None])}
  ds = tf.data.Dataset.from_generator(lambda : dataset, return_types, return_shapes)
  return ds

tf_train_ds = to_tf_dataset(train_ds)
# tf_train_ds_2 = to_tf_dataset(train_ds_2)
tf_valid_ds = to_tf_dataset(valid_ds)

# tf_train_ds_1
# tf_train_ds_2

# tf_train_ds = tf_train_ds_1.concatenate(tf_train_ds_2)

def create_dataset(dataset, cache_path=None, batch_size=4,
                   buffer_size= 1000, shuffling=True):
    if cache_path is not None:
        dataset = dataset.cache(cache_path)
    dataset = dataset.repeat()
    if shuffling:
        dataset = dataset.shuffle(buffer_size)
    dataset = dataset.batch(batch_size)
    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)
    return dataset

tf_train_ds= create_dataset(tf_train_ds, batch_size=batch_size,
                           shuffling=True, cache_path = None)

tf_valid_ds = create_dataset(tf_valid_ds, batch_size=batch_size,
                           shuffling=False, cache_path = None)

tf_train_ds

"""## Training

Saving lowest val_loss model checkpoint
"""

model = TFT5ForConditionalGeneration.from_pretrained(model_name)

checkpoint_path = '/content/drive/MyDrive/Datasets/Base_QG/training/T5-base-0002-0.2930.ckpt'
model.load_weights(checkpoint_path)
model.compile(optimizer=optimizer)

checkpoint_filepath = "T5-base-{epoch:04d}-{val_loss:.4f}.ckpt"
model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(
    filepath=checkpoint_filepath,
    save_weights_only=False,
    monitor='val_loss',
    mode='min',
    save_best_only=True)

train_ds

epochs_done = 0
total_num_of_epochs = 2
ntrain = len(train_ds)
nvalid = len(valid_ds)
steps = ntrain // batch_size
valid_steps = nvalid // batch_size
print("Total Steps: ", steps)
print("Total Validation Steps: ", valid_steps)
model.fit(tf_train_ds, epochs=total_num_of_epochs, steps_per_epoch=steps, validation_data=tf_valid_ds, validation_steps=valid_steps, initial_epoch=epochs_done, callbacks=[model_checkpoint_callback])

"""# Saving Model"""

model.save_pretrained(f'{model_name}-epochs={total_num_of_epochs}')

saved_model_dir_src = f'{model_name}-epochs={total_num_of_epochs}'
saved_model_dir_dest = "/content/drive/MyDrive/Datasets/Base_QG/training/"

!cp -r {saved_model_dir_src} {saved_model_dir_dest}

"""# Loading Saved Model"""

# !gdown --folder 1-cdY1rW29Q7DTns0DfGZ_ZkkhSWy7JCW

model_name = "t5-base"
tokenizer = AutoTokenizer.from_pretrained(model_name)
optimizer = tf.keras.optimizers.Adam(learning_rate)

model = TFT5ForConditionalGeneration.from_pretrained('t5-base')
checkpoint_path = '/content/drive/MyDrive/Datasets/Base_QG/training/squad-lr5e-5/T5-base-0002-0.2930.ckpt'
model.load_weights(checkpoint_path)

model.compile(optimizer=optimizer)

"""# Inference"""

import pickle
from tqdm import tqdm

"""**Inference on dataset**"""

inference_ds = valid_ds

len(inference_ds['input_ids'])

generated_questions = list()

for i in tqdm(range(0, len(inference_ds['input_ids']), 151)):
  output_sequences = model.generate(
      input_ids=inference_ds["input_ids"][i:i+151],
      attention_mask=inference_ds["attention_mask"][i:i+151],
      max_length=decoder_max_len,
      top_p=0.95,
      top_k=50,
      repetition_penalty=float(2)
  )
  q = tokenizer.batch_decode(output_sequences, skip_special_tokens=True)
  generated_questions.extend(q)

"""**Inference file name**"""

inferences_file_name = "generated_questions.pickle"

"""**Saving inference**"""

with open(inferences_file_name, 'wb') as f:
    pickle.dump(generated_questions, f)

import os
size_in_mb = os.path.getsize(f"/content/{inferences_file_name}") / 10**6
print(f'{inferences_file_name} size: {size_in_mb}MB')

!cp {inferences_file_name} "/content/drive/MyDrive/Datasets/Base_QG/training"

"""**Loading inference**"""

inference_file_src = f"/content/drive/MyDrive/Datasets/Base_QG/training/{inferences_file_name}"
inference_file_dist = inferences_file_name

!cp {inference_file_src} {inference_file_dist}

with open(f"/content/drive/MyDrive/Datasets/Base_QG/training/squad-lr5e-5/{inferences_file_name}", 'rb') as f:
    generated_questions = pickle.load(f)

print('generated_questions is', len(generated_questions))

print(generated_questions[:10])

"""# Evaluation"""

golden_questions = list()

for idx in range(len( inference_ds)):
  l = list()
  l.append(inference_ds['question'][idx])
  golden_questions.append(l)

inference_ds['question'][0]

type(golden_questions)

print((golden_questions[0]))
print((generated_questions[0]))

"""## Bleu metric
for more details about the metric:  https://huggingface.co/spaces/evaluate-metric/bleu
"""

import evaluate
bleu = evaluate.load("bleu")

bleu_score = bleu.compute(predictions=generated_questions, references=golden_questions,max_order=1)
print(bleu_score)
bleu_score = bleu.compute(predictions=generated_questions, references=golden_questions,max_order=2)
print(bleu_score)
bleu_score = bleu.compute(predictions=generated_questions, references=golden_questions,max_order=3)
print(bleu_score)
bleu_score = bleu.compute(predictions=generated_questions, references=golden_questions,max_order=4)
print(bleu_score)

"""## ROUGE-L
for more details about the metric: https://huggingface.co/spaces/evaluate-metric/rouge
"""

!pip install rouge_score

rouge_l = evaluate.load('rouge')
rogue_scores = rouge_l.compute(predictions=generated_questions, references=golden_questions)

print(rogue_scores)

"""## METEOR 1.5

"""

!wget http://www.cs.cmu.edu/~alavie/METEOR/download/meteor-1.5.tar.gz

!tar -xf meteor-1.5.tar.gz

with open('golden_questions.txt', 'w') as f:
    for idx in range(len(inference_ds)):
        f.write(f"{inference_ds['question'][idx]}\n")

with open('generated.txt', 'w') as f:
    for question in generated_questions:
        print(type(question))
        f.write(f"{question}\n")

with open('meteor-1.5/generated.txt','r') as f:
  print(f.read())

!java -Xmx2G -jar meteor-1.5/meteor-1.5.jar meteor-1.5/generated.txt meteor-1.5/golden_questions.txt -norm