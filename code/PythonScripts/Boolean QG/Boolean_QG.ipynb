{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sz8sDCvA4SQX"
      },
      "source": [
        "# Setup"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OxqTVVPb4c2s"
      },
      "source": [
        "**Package Installations**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KyZuHcdH6GNo"
      },
      "outputs": [],
      "source": [
        "!pip install transformers\n",
        "!pip install datasets\n",
        "!pip install evaluate\n",
        "!pip install rouge_score"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "atwFaxl04bSA"
      },
      "source": [
        "**Imports**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vtX4VqZ73AMu"
      },
      "outputs": [],
      "source": [
        "import datasets\n",
        "from datasets import load_dataset\n",
        "\n",
        "import transformers\n",
        "from transformers import AutoTokenizer, TFT5ForConditionalGeneration\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import evaluate\n",
        "\n",
        "from tqdm import tqdm\n",
        "\n",
        "import pickle"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u0TVheShLB2c"
      },
      "source": [
        "**Hyperparameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ycrqawCUE3wz"
      },
      "outputs": [],
      "source": [
        "task_prefix = 'generate boolean question: ' # task_prefix + \"true or false\" + context --> boolean question\n",
        "learning_rate = 3e-4\n",
        "encoder_max_len = 500\n",
        "decoder_max_len = 70\n",
        "batch_size = 8"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5UgN1eJOFf4F"
      },
      "source": [
        "**Tokenizer & Optimizer**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yIZeOxPeFn1t"
      },
      "outputs": [],
      "source": [
        "model_name = \"t5-small\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_name)\n",
        "optimizer = tf.keras.optimizers.AdamW(learning_rate)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g-eRhNLT4tux"
      },
      "source": [
        "# Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iGcUsfLV40WS"
      },
      "source": [
        "## Loading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qXtO6B0JIm4y"
      },
      "outputs": [],
      "source": [
        "save_folder_path = \"/content/drive/MyDrive/Datasets/BoolQG\"\n",
        "\n",
        "boolq_data_files = {\n",
        "      \"train\": save_folder_path + \"/\" + \"boolq-train-original-encoded.json\",\n",
        "      \"validation\": save_folder_path + \"/\" + \"boolq-valid-original-encoded.json\",\n",
        "  }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "umXUXuDO46iv"
      },
      "outputs": [],
      "source": [
        "boolq_train_ds = load_dataset(\"json\", data_files=boolq_data_files, split='train')\n",
        "boolq_valid_ds = load_dataset(\"json\", data_files=boolq_data_files, split='validation')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MzPwqEU3_4S1"
      },
      "outputs": [],
      "source": [
        "print(boolq_train_ds.features)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sSd1iJdwB-m-"
      },
      "outputs": [],
      "source": [
        "train_ds = boolq_train_ds\n",
        "valid_ds = boolq_valid_ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVI9kwGn_pG2"
      },
      "source": [
        "## Encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0fAJO9uHNKL5"
      },
      "outputs": [],
      "source": [
        "# def encode(example, encoder_max_len=encoder_max_len, decoder_max_len=decoder_max_len):\n",
        "#     context = example['passage']\n",
        "#     answer = str(example['answer'])\n",
        "\n",
        "#     input = task_prefix + answer + ' ' + 'context: ' + context\n",
        "#     output = example['question']\n",
        "\n",
        "#     encoder_inputs = tokenizer(input, truncation=True,\n",
        "#                                return_tensors='tf', max_length=encoder_max_len,\n",
        "#                               pad_to_max_length=True)\n",
        "#     decoder_inputs = tokenizer(output, truncation=True,\n",
        "#                                return_tensors='tf', max_length=decoder_max_len,\n",
        "#                               pad_to_max_length=True)\n",
        "\n",
        "#     # Shapes come from the encoder_max_len and decoder_max_len in hyperparameters section\n",
        "#     input_ids = encoder_inputs['input_ids'][0] # Shape before flattening: input_ids.shape= (1, 500) [[1,1,3,...]]\n",
        "#     input_attention = encoder_inputs['attention_mask'][0] # Shape before flattening: attension_mask.shape= (1, 500)\n",
        "#     target_ids = decoder_inputs['input_ids'][0] # Shape before flattening: target_ids.shape= (1, 70)\n",
        "#     target_attention = decoder_inputs['attention_mask'][0] # Shape before flattening: target_attention.shape= (1, 70)\n",
        "\n",
        "#     outputs = {'input_ids':input_ids, 'attention_mask': input_attention,\n",
        "#                'labels':target_ids, 'decoder_attention_mask':target_attention}\n",
        "#     return outputs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NYb7Tgp1Y_Ht"
      },
      "outputs": [],
      "source": [
        "# boolq_train_ds = boolq_train_ds.map(encode)\n",
        "# boolq_valid_ds = boolq_valid_ds.map(encode)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72nbZexdoQoE"
      },
      "source": [
        "**Save encoded datasets to Drive (requires mounting Drive)**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ak2i7wuYgttD"
      },
      "outputs": [],
      "source": [
        "# save_folder_path = \"/content/drive/MyDrive/Datasets/BoolQG\"\n",
        "\n",
        "# boolq_train_ds.to_json(save_folder_path + \"/\" + \"boolq-train-original-encoded.json\")\n",
        "# boolq_valid_ds.to_json(save_folder_path + \"/\" + \"boolq-valid-original-encoded.json\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bvrPoWxFM2HX"
      },
      "source": [
        "## To Tensorflow PrefetchDataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g5VO0PI3yBHw"
      },
      "source": [
        "**FlatMapDataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XUydnR3Ka-Yo"
      },
      "outputs": [],
      "source": [
        "def to_tf_dataset(dataset):\n",
        "  columns = ['input_ids', 'attention_mask', 'labels', 'decoder_attention_mask']\n",
        "  dataset.set_format(type='tensorflow', columns=columns)\n",
        "  return_types = {'input_ids':tf.int32, 'attention_mask':tf.int32,\n",
        "                'labels':tf.int32, 'decoder_attention_mask':tf.int32,  }\n",
        "  return_shapes = {'input_ids': tf.TensorShape([None]), 'attention_mask': tf.TensorShape([None]),\n",
        "                  'labels': tf.TensorShape([None]), 'decoder_attention_mask':tf.TensorShape([None])}\n",
        "  ds = tf.data.Dataset.from_generator(lambda : dataset, return_types, return_shapes)\n",
        "  return ds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c61QywAEb7-W"
      },
      "outputs": [],
      "source": [
        "tf_train_ds = to_tf_dataset(train_ds)\n",
        "tf_valid_ds = to_tf_dataset(valid_ds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KRh47x7N_gxN"
      },
      "outputs": [],
      "source": [
        "tf_train_ds"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6Ry4A39yFd3"
      },
      "source": [
        "**PrefetchDataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XkCoA-YcfdKj"
      },
      "outputs": [],
      "source": [
        "def create_dataset(dataset, cache_path=None, batch_size=4,\n",
        "                   buffer_size= 1000, shuffling=True):\n",
        "    if cache_path is not None:\n",
        "        dataset = dataset.cache(cache_path)\n",
        "    dataset = dataset.repeat()\n",
        "    if shuffling:\n",
        "        dataset = dataset.shuffle(buffer_size)\n",
        "    dataset = dataset.batch(batch_size)\n",
        "    dataset = dataset.prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    return dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FbjNnG1YC8tw"
      },
      "outputs": [],
      "source": [
        "tf_train_ds= create_dataset(tf_train_ds, batch_size=batch_size,\n",
        "                           shuffling=True, cache_path = None)\n",
        "tf_valid_ds = create_dataset(tf_valid_ds, batch_size=batch_size,\n",
        "                           shuffling=False, cache_path = None)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "43Qb9gdzNFIZ"
      },
      "source": [
        "# Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I3BvbERTs0sp"
      },
      "source": [
        "**Training parameters**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GKWUu9zrqtrY"
      },
      "outputs": [],
      "source": [
        "epochs_done = 0\n",
        "total_num_of_epochs = 3\n",
        "ntrain = len(train_ds)\n",
        "# nvalid = len(valid_ds)\n",
        "steps = ntrain // batch_size\n",
        "# valid_steps = nvalid // batch_size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HTzUdYG4jNpA"
      },
      "outputs": [],
      "source": [
        "try:\n",
        "    model\n",
        "except NameError:\n",
        "    print(\"WARNING: Model was NOT loaded.\")\n",
        "    model = TFT5ForConditionalGeneration.from_pretrained(model_name) #options: t5-small, t5-base, t5-large, t5-3b, t5-11b\n",
        "else:\n",
        "    print(\"Model was loaded\")\n",
        "\n",
        "model.compile(optimizer=optimizer)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ik8Hdl8zMQ6F"
      },
      "source": [
        "**Callbacks**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DhpIJz21v5D-"
      },
      "outputs": [],
      "source": [
        "import shutil\n",
        "from tensorflow import keras\n",
        "\n",
        "epoch_num = epochs_done + 1\n",
        "saved_model_dir_dest = \"/content/drive/MyDrive/BoolQGModels\"\n",
        "\n",
        "class SaveMyModel(keras.callbacks.Callback):\n",
        "\n",
        "    def on_epoch_end(self, batch, logs={}):\n",
        "        global epoch_num\n",
        "        saved_model_dir_src = f'{model_name}-epochs={epoch_num}-original-paperhp-all'\n",
        "        model.save_pretrained(saved_model_dir_src)\n",
        "        shutil.copytree(f'/content/{saved_model_dir_src}', saved_model_dir_dest + '/' + saved_model_dir_src, dirs_exist_ok=True)\n",
        "        epoch_num = epoch_num + 1\n",
        "\n",
        "saveMyModel = SaveMyModel()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6CAPxr5fY3Lx"
      },
      "outputs": [],
      "source": [
        "print(\"Total Steps: \", steps)\n",
        "# print(\"Total Validation Steps: \", valid_steps)\n",
        "# model.fit(tf_train_ds, epochs=total_num_of_epochs, steps_per_epoch=steps, validation_data=tf_valid_ds, validation_steps=valid_steps, initial_epoch=epochs_done, callbacks=[saveMyModel])\n",
        "model.fit(tf_train_ds, epochs=total_num_of_epochs, steps_per_epoch=steps, initial_epoch=epochs_done, callbacks=[saveMyModel])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RHW0B5hHebp2"
      },
      "source": [
        "# Saving Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dpoih_fPZtKX"
      },
      "outputs": [],
      "source": [
        "model.save_pretrained(f'{model_name}-epochs={total_num_of_epochs}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BuiXUo_qojAT"
      },
      "outputs": [],
      "source": [
        "saved_model_dir_src = f'{model_name}-epochs={total_num_of_epochs}'\n",
        "saved_model_dir_dest = \"/content/drive/MyDrive/BoolQGModels\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2oPOWS_8nMBB"
      },
      "outputs": [],
      "source": [
        "!cp -r {saved_model_dir_src} {saved_model_dir_dest}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VYveqxwsrvOb"
      },
      "source": [
        "# Loading Saved Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VCiIjzAKsLiw"
      },
      "outputs": [],
      "source": [
        "saved_model_dir_src = \"/content/drive/MyDrive/BoolQGModels/t5-small-epochs=20-original\" #@param {type:\"string\"}\n",
        "model_name = 't5-small' #@param [\"t5-small\", \"t5-base\", \"t5-large\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6KPlSSczw1F2"
      },
      "outputs": [],
      "source": [
        "model = TFT5ForConditionalGeneration.from_pretrained(saved_model_dir_src)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Inference"
      ],
      "metadata": {
        "id": "am0bQ9rWF5cn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "to_tf_dataset(boolq_valid_ds)\n",
        "inference_ds = boolq_valid_ds"
      ],
      "metadata": {
        "id": "qkegiIi7JUjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "extracted_answers = list()\n",
        "\n",
        "for i in tqdm(range(0, len(inference_ds['input_ids']), 100)):\n",
        "  output_sequences = model.generate(\n",
        "      input_ids=inference_ds[\"input_ids\"][i:i+100],\n",
        "      attention_mask=inference_ds[\"attention_mask\"][i:i+100],\n",
        "      max_length=decoder_max_len,\n",
        "      top_p=0.95,\n",
        "      top_k=50,\n",
        "      repetition_penalty=float(2)\n",
        "  )\n",
        "  a = tokenizer.batch_decode(output_sequences, skip_special_tokens=True)\n",
        "  extracted_answers.extend(a)"
      ],
      "metadata": {
        "id": "ZHQT5HYnAS8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('your_file.txt', 'w') as f:\n",
        "    for line in extracted_answers:\n",
        "        f.write(f\"{line}\\n\")"
      ],
      "metadata": {
        "id": "cVxvNVfMZ825"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Inference file name**"
      ],
      "metadata": {
        "id": "KM81lDeRGH31"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inference_file_name = 'boolean_questions_epochs=2.pickle'"
      ],
      "metadata": {
        "id": "qklrdmcyGKfS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Saving inference**"
      ],
      "metadata": {
        "id": "MJCtVV6FLHRf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(extracted_answers))"
      ],
      "metadata": {
        "id": "LecqoEUKKuUq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "U6UOKOtqkVwv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(inference_file_name, 'wb') as f:\n",
        "    pickle.dump(extracted_answers, f)"
      ],
      "metadata": {
        "id": "K4-8nXz2LHRg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "size_in_mb = os.path.getsize(f\"/content/{inference_file_name}\") / 10**6\n",
        "print(f'{inference_file_name} size: {size_in_mb}MB')"
      ],
      "metadata": {
        "id": "6XAh4gt4LcRF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp {inference_file_name} \"/content/drive/MyDrive/AnswerExtractionModels\""
      ],
      "metadata": {
        "id": "RW4NJeUM0hg-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Loading inference**"
      ],
      "metadata": {
        "id": "dV71B0OR3bFO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "inference_file_src = f\"/content/drive/MyDrive/AnswerExtractionModels/{inference_file_name}\"\n",
        "inference_file_dist = inference_file_name"
      ],
      "metadata": {
        "id": "aHjUPX_lFA7K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!cp {inference_file_src} {inference_file_dist}"
      ],
      "metadata": {
        "id": "L_tcPRrTGlpe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(inference_file_name, 'rb') as f:\n",
        "    extracted_answers = pickle.load(f)\n",
        "\n",
        "print('extracted_answers is', len(extracted_answers))"
      ],
      "metadata": {
        "id": "lDi2ZEFq1Pvr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluation"
      ],
      "metadata": {
        "id": "LRaR2jf4xUQB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(boolq_valid_ds['question']))\n",
        "print(len(extracted_answers))"
      ],
      "metadata": {
        "id": "6PIJK8-9sF8l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**BLEU**"
      ],
      "metadata": {
        "id": "CSnoJ7qOxnnp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fS_zz6hl5pPz"
      },
      "outputs": [],
      "source": [
        "bleu = evaluate.load(\"bleu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LsyvgqB254ec"
      },
      "outputs": [],
      "source": [
        "bleu1_score = bleu.compute(predictions=extracted_answers, references=boolq_valid_ds['question'],max_order=1)\n",
        "print(bleu1_score)\n",
        "bleu2_score = bleu.compute(predictions=extracted_answers, references=boolq_valid_ds['question'],max_order=2)\n",
        "print(bleu2_score)\n",
        "bleu3_score = bleu.compute(predictions=extracted_answers, references=boolq_valid_ds['question'],max_order=3)\n",
        "print(bleu3_score)\n",
        "bleu4_score = bleu.compute(predictions=extracted_answers, references=boolq_valid_ds['question'],max_order=4)\n",
        "print(bleu4_score)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ROGUE-L**"
      ],
      "metadata": {
        "id": "TaEwkLgWxpKn"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzqjyKt6GJlW"
      },
      "outputs": [],
      "source": [
        "rouge_l = evaluate.load('rouge')\n",
        "rogue_scores = rouge_l.compute(predictions=extracted_answers, references=boolq_valid_ds['question'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ts2kJP3EGLWV"
      },
      "outputs": [],
      "source": [
        "print(rogue_scores)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**METOER**"
      ],
      "metadata": {
        "id": "Xwu9Hc1wxwWE"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1qWBf9hGGaHL"
      },
      "outputs": [],
      "source": [
        "meteor = evaluate.load('meteor')\n",
        "meteor_score = meteor.compute(predictions=extracted_answers, references=boolq_valid_ds['question'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "W3Yg1b6dGb0b"
      },
      "outputs": [],
      "source": [
        "print(meteor_score)\n",
        "\n",
        "# {'meteor': 0.45575705972743036} base"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Calculate & Save Metrics"
      ],
      "metadata": {
        "id": "Aq-dhP83XIXo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "results_file_name = 't5-base-epochs=10:15-lr=3e-4-optimizer=adamW Fix Results'\n",
        "\n",
        "bleu = evaluate.load(\"bleu\")\n",
        "rouge_l = evaluate.load('rouge')\n",
        "meteor = evaluate.load('meteor')\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained('t5-base')\n",
        "\n",
        "to_tf_dataset(boolq_valid_ds)\n",
        "inference_ds = boolq_valid_ds"
      ],
      "metadata": {
        "id": "eQXPRhStXUlR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "results = list()\n",
        "\n",
        "for i in tqdm(range(10, 15 + 1)):\n",
        "  saved_model_dir_src = f'/content/drive/MyDrive/BoolQGModels/t5-base-epochs={i}-original-paperhp'\n",
        "  model = TFT5ForConditionalGeneration.from_pretrained(saved_model_dir_src)\n",
        "  extracted_answers = list()\n",
        "  for i in tqdm(range(0, len(inference_ds['input_ids']), 100)):\n",
        "    output_sequences = model.generate(\n",
        "        input_ids=inference_ds[\"input_ids\"][i:i+100],\n",
        "        attention_mask=inference_ds[\"attention_mask\"][i:i+100],\n",
        "        max_length=decoder_max_len,\n",
        "        top_p=0.95,\n",
        "        top_k=50,\n",
        "        repetition_penalty=float(2)\n",
        "    )\n",
        "    a = tokenizer.batch_decode(output_sequences, skip_special_tokens=True)\n",
        "    extracted_answers.extend(a)\n",
        "\n",
        "  bleu1_score = bleu.compute(predictions=extracted_answers, references=boolq_valid_ds['question'],max_order=1)\n",
        "  bleu2_score = bleu.compute(predictions=extracted_answers, references=boolq_valid_ds['question'],max_order=2)\n",
        "  bleu3_score = bleu.compute(predictions=extracted_answers, references=boolq_valid_ds['question'],max_order=3)\n",
        "  bleu4_score = bleu.compute(predictions=extracted_answers, references=boolq_valid_ds['question'],max_order=4)\n",
        "  rogue_scores = rouge_l.compute(predictions=extracted_answers, references=boolq_valid_ds['question'])\n",
        "  meteor_score = meteor.compute(predictions=extracted_answers, references=boolq_valid_ds['question'])\n",
        "\n",
        "  current_epoch_results = [bleu1_score, bleu2_score, bleu3_score, bleu4_score, rogue_scores, meteor_score]\n",
        "  results.append(current_epoch_results)"
      ],
      "metadata": {
        "id": "P4PdWufna58w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle\n",
        "\n",
        "with open(results_file_name, 'wb') as f:\n",
        "    pickle.dump(results, f)\n",
        "!cp {results_file_name} \"/content/drive/MyDrive/BoolQGModels\""
      ],
      "metadata": {
        "id": "nsZ2MA3sah6u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open(results_file_name, 'rb') as f:\n",
        "    results = pickle.load(f)\n",
        "\n",
        "for l in results:\n",
        "  print(l)"
      ],
      "metadata": {
        "id": "f13ADEuKox2T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(extracted_answers)"
      ],
      "metadata": {
        "id": "BpdP_lgsTv7E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "with open('your_file.txt', 'w') as f:\n",
        "    for line in extracted_answers:\n",
        "        f.write(f\"{line}\\n\")"
      ],
      "metadata": {
        "id": "sTFMvgskT_9U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Visualize results"
      ],
      "metadata": {
        "id": "__rMbLGGr_hT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Get scores in seperate lists"
      ],
      "metadata": {
        "id": "6PxoV0JHsB65"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "UiJ1H4B_sKQW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bleu1_scores = list()\n",
        "bleu2_scores = list()\n",
        "bleu3_scores = list()\n",
        "bleu4_scores = list()\n",
        "roguel_scores = list()\n",
        "meteor_scores = list()"
      ],
      "metadata": {
        "id": "i6qHSWHTtojC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(0, 20):\n",
        "  bleu1_scores.append(results[i][0]['bleu'])\n",
        "  bleu2_scores.append(results[i][1]['bleu'])\n",
        "  bleu3_scores.append(results[i][2]['bleu'])\n",
        "  bleu4_scores.append(results[i][3]['bleu'])\n",
        "  roguel_scores.append(results[i][4]['rougeL'])\n",
        "  meteor_scores.append(results[i][5]['meteor'])"
      ],
      "metadata": {
        "id": "AFbEfFUFsBZK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "print(np.argmax(bleu1_scores) + 1)"
      ],
      "metadata": {
        "id": "o7LgboA3u-GH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sns.scatterplot(bleu1_scores)"
      ],
      "metadata": {
        "id": "o3MqGVTKuMAF"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "collapsed_sections": [
        "sz8sDCvA4SQX",
        "g-eRhNLT4tux",
        "iGcUsfLV40WS",
        "kVI9kwGn_pG2",
        "bvrPoWxFM2HX",
        "43Qb9gdzNFIZ",
        "RHW0B5hHebp2",
        "am0bQ9rWF5cn",
        "LRaR2jf4xUQB",
        "Aq-dhP83XIXo",
        "__rMbLGGr_hT"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}